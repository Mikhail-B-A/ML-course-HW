{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfc03c9",
   "metadata": {
    "papermill": {
     "duration": 0.002669,
     "end_time": "2024-12-18T09:36:19.366622",
     "exception": false,
     "start_time": "2024-12-18T09:36:19.363953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Задание со звездочкой 17. Dunn index\r\n",
    "Реализуйте Dunn Index. Будет засчитываться не абы-какая реализация, а соответствующая по стилю и оформлению реализации метрик в sklearn: обязательны докстринги, валидаторы и все такое.\r\n",
    "\r\n",
    "То, как реализованы другие метрики, можно посмотреть [тут](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/metrics/cluster/_unsupervised.py#L195)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0418e0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:36:19.373602Z",
     "iopub.status.busy": "2024-12-18T09:36:19.373093Z",
     "iopub.status.idle": "2024-12-18T09:36:21.223051Z",
     "shell.execute_reply": "2024-12-18T09:36:21.221630Z"
    },
    "papermill": {
     "duration": 1.856912,
     "end_time": "2024-12-18T09:36:21.226123",
     "exception": false,
     "start_time": "2024-12-18T09:36:19.369211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils._param_validation import validate_params\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "@validate_params({\n",
    "    'X': [np.ndarray],\n",
    "    'labels': [np.ndarray],\n",
    "    'metric': [str],\n",
    "})\n",
    "def dunn_score(X, labels, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    Compute the Dunn Index for a clustering solution (based on the Wikipedia definition).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (n_samples, n_features)\n",
    "        The data points.\n",
    "\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        Cluster labels for each point.\n",
    "\n",
    "    metric : str, default='euclidean'\n",
    "        The metric to use for calculating distances.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dunn_index : float\n",
    "        The Dunn Index for the given clustering. Higher values indicate better-defined clusters.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The Dunn Index is defined as the ratio between the minimum inter-cluster distance\n",
    "    and the maximum intra-cluster distance:\n",
    "\n",
    "        Dunn Index = min_inter_cluster_distance / max_intra_cluster_distance\n",
    "\n",
    "    Reference: https://en.wikipedia.org/wiki/Dunn_index\n",
    "    \"\"\"\n",
    "    X = check_array(X, ensure_min_samples=2, ensure_min_features=1)\n",
    "    labels = check_array(labels, ensure_2d=False, dtype=int)\n",
    "\n",
    "    if X.shape[0] != labels.shape[0]:\n",
    "        raise ValueError(\"The number of samples in X and labels must match.\")\n",
    "\n",
    "    # Unique clusters\n",
    "    clusters = np.unique(labels)\n",
    "    if len(clusters) < 2:\n",
    "        raise ValueError(\"The number of unique clusters must be at least 2.\")\n",
    "\n",
    "    # Compute centroids of each cluster\n",
    "    centroids = np.array([X[labels == cluster].mean(axis=0) for cluster in clusters])\n",
    "\n",
    "    # Compute max intra-cluster distance (to centroid)\n",
    "    max_intra_cluster_distance = 0\n",
    "    for cluster, centroid in zip(clusters, centroids):\n",
    "        cluster_points = X[labels == cluster]\n",
    "        intra_distances = pairwise_distances(cluster_points, [centroid], metric=metric)\n",
    "        max_intra_cluster_distance = max(max_intra_cluster_distance, intra_distances.max())\n",
    "\n",
    "    if max_intra_cluster_distance == 0:\n",
    "        raise ValueError(\"All points in the same cluster are identical.\")\n",
    "\n",
    "    # Compute min inter-cluster distance (between centroids)\n",
    "    inter_cluster_distances = pairwise_distances(centroids, metric=metric)\n",
    "    np.fill_diagonal(inter_cluster_distances, np.inf)\n",
    "    min_inter_cluster_distance = inter_cluster_distances.min()\n",
    "\n",
    "    # Compute Dunn Index\n",
    "    dunn_index = min_inter_cluster_distance / max_intra_cluster_distance\n",
    "\n",
    "    return dunn_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5448b062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:36:21.232640Z",
     "iopub.status.busy": "2024-12-18T09:36:21.232027Z",
     "iopub.status.idle": "2024-12-18T09:36:27.777544Z",
     "shell.execute_reply": "2024-12-18T09:36:27.776217Z"
    },
    "papermill": {
     "duration": 6.552287,
     "end_time": "2024-12-18T09:36:27.780702",
     "exception": false,
     "start_time": "2024-12-18T09:36:21.228415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Simple verification on synthetic data:\n",
      "Dunn Index: 10.303433516719945\n",
      "Dunn Index by torch: tensor(10.3034, dtype=torch.float64)\n",
      "\n",
      "2. Verification with one cluster (must be ValueError):\n",
      "Caught expected error for single cluster: The number of unique clusters must be at least 2.\n",
      "\n",
      "3. Verification for for poorly-separated clusters:\n",
      "Dunn Index: 1.0376130343703116\n",
      "Dunn Index by torch: tensor(1.0376, dtype=torch.float64)\n",
      "\n",
      "4. Verification for identical points:\n",
      "Caught expected error for identical points: All points in the same cluster are identical.\n",
      "\n",
      "5. Manhattan mertic test:\n",
      "Dunn Index: 5.6687513821301545\n",
      "Dunn Index by torch: tensor(5.1316, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import torch\n",
    "from torchmetrics.functional.clustering import dunn_index\n",
    "\n",
    "# tensor Dunn index for comparison\n",
    "def tensor_dunn_score(X, y):\n",
    "    \n",
    "    data = torch.tensor(X)\n",
    "    labels = torch.tensor(y)\n",
    "    \n",
    "    return dunn_index(data, labels)\n",
    "\n",
    "\n",
    "# 1. Simple verification on synthetic data\n",
    "print(\"1. Simple verification on synthetic data:\")\n",
    "X, y = make_blobs(n_samples=10, centers=2, cluster_std=0.5, random_state=42)\n",
    "print(\"Dunn Index:\", dunn_score(X, y))\n",
    "print(\"Dunn Index by torch:\", tensor_dunn_score(X, y))\n",
    "\n",
    "# 2. Verification with one cluster (must be ValueError)\n",
    "print(\"\\n2. Verification with one cluster (must be ValueError):\")\n",
    "try:\n",
    "    X_single, y_single = X, np.zeros(X.shape[0])\n",
    "    dunn_score(X_single, y_single)\n",
    "except ValueError as e:\n",
    "    print(\"Caught expected error for single cluster:\", e)\n",
    "\n",
    "# 3. Verification for bad clusters\n",
    "print(\"\\n3. Verification for for poorly-separated clusters:\")\n",
    "X_bad, y_bad = make_blobs(n_samples=10, centers=2, cluster_std=5.0, random_state=42)\n",
    "print(\"Dunn Index:\", dunn_score(X_bad, y_bad))\n",
    "print(\"Dunn Index by torch:\", tensor_dunn_score(X_bad, y_bad))\n",
    "\n",
    "# 4. Verification for identical points\n",
    "print(\"\\n4. Verification for identical points:\")\n",
    "X_identical = np.array([[1, 1], [1, 1], [5, 5], [5, 5]])\n",
    "y_identical = np.array([0, 0, 1, 1])\n",
    "try:\n",
    "    print(\"Dunn Index:\", dunn_score(X_identical, y_identical))\n",
    "except ValueError as e:\n",
    "    print(\"Caught expected error for identical points:\", e)\n",
    "\n",
    "# 5. Manhattan mertic test\n",
    "print(\"\\n5. Manhattan mertic test:\")\n",
    "X_custom, y_custom = make_blobs(n_samples=10, centers=2, cluster_std=1.0, random_state=42)\n",
    "print(\"Dunn Index:\", dunn_score(X_custom, y_custom, metric='manhattan'))\n",
    "print(\"Dunn Index by torch:\", tensor_dunn_score(X_custom, y_custom))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.624245,
   "end_time": "2024-12-18T09:36:29.412287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T09:36:15.788042",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
